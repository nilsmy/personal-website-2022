<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Psychometrics on Nils Myszkowski</title>
    <link>/categories/psychometrics/</link>
    <description>Recent content in Psychometrics on Nils Myszkowski</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sat, 01 Jan 2022 00:00:00 +0000</lastBuildDate><atom:link href="/categories/psychometrics/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>jrt – Item Response Theory Modeling and Scoring for Judgment Data</title>
      <link>/r-packages/jrt/</link>
      <pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>/r-packages/jrt/</guid>
      <description>What it&amp;rsquo;s about   The goal of jrt is to provide tools to use Item-Response Theory (IRT) models on judgment data, especially in the context of the Consensual Assessment Technique, as presented in Myszkowski (2021).
The goal of jrt is to provide tools to use Item-Response Theory (IRT) models on judgment data, especially in the context of the Consensual Assessment Technique, as presented in Myszkowski (2021).
 Myszkowski, N.</description>
    </item>
    
    <item>
      <title>Accounting for Variable Task Discrimination in Divergent Thinking Fluency Measurement – An Example of the Benefits of a 2-Parameter Poisson Counts Model and its Bifactor Extension Over the Rasch Poisson Counts Model</title>
      <link>/publications/2021-2ppcm/</link>
      <pubDate>Sun, 12 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>/publications/2021-2ppcm/</guid>
      <description>What it’s about In this paper, we introduce new psychometric models for count/fluency tasks (tasks in which individuals have to provide many instances). Notably, we extent the Rasch Poisson Counts Model (RPCM) to account for variable discrimination (2-Parameter Poisson Counts Model) and to account for local dependencies/nuisance factors (Bifactor 2-Parameter Poisson Counts Model).
 Abstract Fluency tasks are among the most common item formats for the assessment of certain cognitive abilities, such as verbal fluency or divergent thinking.</description>
    </item>
    
    <item>
      <title>A Mokken Scale Analysis of the Last Series of the Standard Progressive Matrices (SPM-LS)</title>
      <link>/publications/2020-mokken/</link>
      <pubDate>Tue, 12 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/publications/2020-mokken/</guid>
      <description>What it’s about In this paper, I reanalyze a dataset for a special issue of Journal of Intelligence. The analysis uses the framework of Mokken Scale Analysis (MSA), which is a non-parametric approach to relations between item responses and attributes (i.e. Item-Response Theory).
 Abstract Raven’s Standard Progressive Matrices (Raven 1941) is a widely used 60-item long measure of general mental ability. It was recently suggested that, for situations where taking this test is too time consuming, a shorter version, comprised of only the last series of the Standard Progressive Matrices (Myszkowski and Storme 2018) could be used, while preserving satisfactory psychometric properties (Garcia-Garzon et al.</description>
    </item>
    
    <item>
      <title>Same Test, Better Scores – Boosting the Reliability of Short Online Intelligence Recruitment Tests with Nested Logit Item Response Theory Models</title>
      <link>/publications/2019-same_test/</link>
      <pubDate>Wed, 10 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>/publications/2019-same_test/</guid>
      <description>What it’s about In this paper, we propose to generalize the use of Nested Logit Models and implement its use for online personnel selection procedures that use reasoning tests with multiple choices (e.g., matrix-type tests). We find that using such models results in gains of reliability, especially at low ability levels.
 Abstract Assessing job applicants’ general mental ability online poses psychometric challenges due to the necessity of having brief but accurate tests.</description>
    </item>
    
    <item>
      <title>A snapshot of g? Binary and polytomous item-response theory investigations of the last series of the Standard Progressive Matrices (SPM-LS)</title>
      <link>/publications/2018-intelligence/</link>
      <pubDate>Wed, 12 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/publications/2018-intelligence/</guid>
      <description>What it’s about In this paper, we propose the use of the last series of the last series of the Standard Progressive Matrices (SPM-LS) as a viable snapshot measure of g. We provide an extensive Item-Response Theory (IRT) analysis of the instrument, based on the binary (pass/fail) and nominal (response categories) data.
 Abstract Raven’s progressive matrices (Raven, 1941) are extremely popular measures of general mental ability. However, their length may not suit every researcher’s or practitioner’s needs.</description>
    </item>
    
  </channel>
</rss>
